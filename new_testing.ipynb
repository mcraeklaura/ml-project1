{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "For Project 1 we are participating in a Kaggle contest using given datasets and information about the datasets. The contest is called Porto Seguroâ€™s Safe Driver Prediction. The purpose of this competition is to see who can make the best predictions with the given dataset. Before we even started to load and analyze the dataset, there was a lot of information about the features presented. There are three types of features, binary, categorical and normal numeric numbers. There is a lot of missing data in the features as well, sometimes being a huge part of the features. We decided that because there are so many different types of features, we needed to fill in missing data differently. A -1 indicates that portion of the data is missing, so for something like binary or categorical, we can't just find an average of 0 and 1, or 1, 2, 3, and so on like we can do using numerical numbers.\n",
    "\n",
    "## Data Preparation and Exploration\n",
    "Using the features provided, we are expected to analyze and preprocess the data. We start out by finding out how many NaNs there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"data/train.csv\")\n",
    "X_orig = dat.loc[:, dat.columns != \"target\"]\n",
    "y_orig = dat.loc[:, \"target\"]\n",
    "count_nan = len(dat) - dat.count()\n",
    "print(\"Number of NaNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a significant amount of NaNs. If we chose to ignore it, or assume that there is reason for these numbers to be missing, we might miss something. We then come up with ways to preprocess the data in a realistic and logical way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_no_neg = X_orig\n",
    "y_no_neg = y_orig\n",
    "cat = pd.DataFrame()\n",
    "bn = pd.DataFrame()\n",
    "norm = pd.DataFrame()\n",
    "ids = X_orig['id']\n",
    "\n",
    "## We ignore the id column for this step\n",
    "for i in X_orig.columns[1:]:\n",
    "    if \"cat\" in i:\n",
    "        # Transform Median\n",
    "        cat[i] = dat.loc[:, i]\n",
    "    elif \"bin\" in i:\n",
    "        # Transform\n",
    "        bn[i] = dat.loc[:, i]\n",
    "    else:\n",
    "        # Do something\n",
    "        norm[i] = dat.loc[:, i]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Features\n",
    "Amount of missing data in each column of the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cat.columns:\n",
    "    tmp = 0\n",
    "    cat.loc[cat[i] == -1, i] = np.median(cat.loc[cat[i] != -1,i])\n",
    "    tmp = tmp + sum(cat[i] == -1)\n",
    "    \n",
    "print(\"Number of -1 in data:\", tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Features\n",
    "Amount of missing data in each column of the binary features (None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in bn.columns:\n",
    "    tmp = 0\n",
    "    tmp = tmp + sum(bn[i] == -1)\n",
    "    print(i, \":\", tmp)\n",
    "    \n",
    "print(\"There are no negatives in bin columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal/Numerical Features\n",
    "Amount of missing data in each column of the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for feature in cat:\n",
    "    temp.append(pd.get_dummies(cat[feature]))\n",
    "\n",
    "new_cat = pd.DataFrame()\n",
    "for feature in temp:\n",
    "    new_cat = pd.concat([new_cat, feature], axis=1)\n",
    "\n",
    "mx = 0\n",
    "for i in norm.columns:\n",
    "    tmp = 0\n",
    "    tmp = tmp + sum(norm[i] == -1)\n",
    "    print(i, \":\", tmp)\n",
    "    if mx < tmp:\n",
    "        mx=tmp\n",
    "\n",
    "print(\"~\", mx/float(len(norm)) * 100, \"% of the data is missing, so we are going to assume that there is significance that the data is missing\")\n",
    "num_missing_per_row = np.zeros(len(norm))\n",
    "tmp = 0\n",
    "for index, row in norm.iterrows():\n",
    "    num_missing_per_row[index] =  sum(row == -1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant amount of data missing in the normal fields, which is concerning. This means that there is most likley no significance for this data being missing. We then decided to use a pipeline to replace the missing values with the mean of the feature. We also scaled the data using a StandardScaler. We decided to use this because there is a huge amount of data, around 500,000 instances. However, only ~3% of the data is in class 1, while 96% is in class 0. Using a z-score can help us vizualize and quickly detect any outliers and if they have anything to do with the instance's class being a 1 or a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_06_bin : 0\n",
      "ps_ind_07_bin : 0\n",
      "ps_ind_08_bin : 0\n",
      "ps_ind_09_bin : 0\n",
      "ps_ind_10_bin : 0\n",
      "ps_ind_11_bin : 0\n",
      "ps_ind_12_bin : 0\n",
      "ps_ind_13_bin : 0\n",
      "ps_ind_16_bin : 0\n",
      "ps_ind_17_bin : 0\n",
      "ps_ind_18_bin : 0\n",
      "ps_calc_15_bin : 0\n",
      "ps_calc_16_bin : 0\n",
      "ps_calc_17_bin : 0\n",
      "ps_calc_18_bin : 0\n",
      "ps_calc_19_bin : 0\n",
      "ps_calc_20_bin : 0\n",
      "ps_ind_01 : 0\n",
      "ps_ind_03 : 0\n",
      "ps_ind_14 : 0\n",
      "ps_ind_15 : 0\n",
      "ps_reg_01 : 0\n",
      "ps_reg_02 : 0\n",
      "ps_reg_03 : 107772\n",
      "ps_car_11 : 5\n",
      "ps_car_12 : 1\n",
      "ps_car_13 : 0\n",
      "ps_car_14 : 42620\n",
      "ps_car_15 : 0\n",
      "ps_calc_01 : 0\n",
      "ps_calc_02 : 0\n",
      "ps_calc_03 : 0\n",
      "ps_calc_04 : 0\n",
      "ps_calc_05 : 0\n",
      "ps_calc_06 : 0\n",
      "ps_calc_07 : 0\n",
      "ps_calc_08 : 0\n",
      "ps_calc_09 : 0\n",
      "ps_calc_10 : 0\n",
      "ps_calc_11 : 0\n",
      "ps_calc_12 : 0\n",
      "ps_calc_13 : 0\n",
      "ps_calc_14 : 0\n",
      "~ 18.1064897885 % of the data is missing, so we are going to assume that there is significance that the data is missing\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "pipe = Pipeline([\n",
    "       (\"remove_neg_ones\", Imputer(missing_values=-1, strategy=\"mean\")),\n",
    "        (\"z-scaling\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "scaled_norm = pd.DataFrame(pipe.fit_transform(norm), columns = norm.columns)\n",
    "X_final = pd.concat([bn, new_cat, scaled_norm], axis=1)\n",
    "X_orig = X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~96% of the data is class 0, and ~3% is class 1. This means any algorithm would have to guess 0 for everything, and it would get a 96% accuracy rate. To become more accurate, the training set can be changed to a 50/50 solution, where 50% of the data is classified at 0 and the other 50% is class 1. This ensures that the model has enough training instances of class 1 to properly make predictions when the test set contains a 1. To make the training set larger, we sample four times the amount of class 1 instances, and the same amount for the class 0 instances with replacement. This ensures that there is a lot of data to train on, and that we have enough variation in the instances that we are choosing from the 1 category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_orig, y_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ones = X_train.loc[y_train==1, :]\n",
    "X_ones = pd.DataFrame(X_ones)\n",
    "X_ones = X_ones.sample(n=(len(X_ones)*4), replace=True)\n",
    "y_ones = y_train[y_train==1]\n",
    "X_zeroes = X_train.loc[y_train==0, :]\n",
    "X_zeroes = pd.DataFrame(X_zeroes)\n",
    "dat_ones = X_ones\n",
    "dat_ones[\"target\"] = [1] * (len(X_ones))\n",
    "dat_f = pd.DataFrame(X_zeroes.sample(n=(len(X_ones)), replace=True))\n",
    "dat_f[\"target\"] = np.zeros(len(dat_f))\n",
    "dat_ones = dat_ones.append(dat_f.sample(n=(len(dat_ones))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shrunk = dat_ones.loc[:, dat_ones.columns != \"target\"]\n",
    "y_shrunk = dat_ones.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this competition, the best predictions are judged based off of these gini functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "     assert( len(actual) == len(pred) )\n",
    "     all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "     all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "     totalLosses = all[:,0].sum()\n",
    "     giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "     giniSum -= (len(actual) + 1) / 2\n",
    "     return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been enough preprocessing and data exploration to test out how the training set works on a model. Using a default Gradient Boosting Classifier, the predictions are put into the gini_normalized function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_shrunk, y_shrunk)\n",
    "predicted = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini score for default GradientBoostingRegressor 0.2763515725664041\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gini score for default GradientBoostingRegressor {gini_normalized(y_test, predicted[:,1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gini score is quite high in comparison to our contenders. Now, the original, non-50/50 training data is put into a default Gradient Boosting Classifier as a comparission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini score for default GradientBoostingRegressor 0.2816102047006163\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gini score for default GradientBoostingRegressor {gini_normalized(y_test, predicted[:,1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict_proba(X_test)\n",
    "#confusion_matrix(y_test, np.round(predicted))\n",
    "#print(np.amin(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini score for default GradientBoostingRegressor 0.27795604630619936\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gini score for default GradientBoostingRegressor {gini_normalized(y_test, predicted[:,1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 50/50 dataset did not do better than the original training set. One hypothesis is that we are training with too many instances of class 1, when in reality, there are not as many in the test set. In the regular training set, there is a realistic amount of class 1 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "There were many obsticles to figure out with this dataset. There was a huge amount of uneven and lost data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference of splits are large (.004 in change)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
